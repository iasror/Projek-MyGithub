{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mglearn\n",
    "np.random.seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# create a synthetic dataset\n",
    "X, y = make_blobs(centers=2, random_state=0)\n",
    "# split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "# Instantiate a model and fit it to the training set\n",
    "lr = LogisticRegression().fit(X_train, y_train)\n",
    "# evaluate the model on the test set\n",
    "print(\"Test set score: {:.2f}\".format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbgAAAEuCAYAAAD89QftAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncIwxxjSJAxxjjDFN4gDHGGNMk/4/rMzMbxThJYEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5728bb8908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train,\n",
    "                         markers='o', ax=ax)\n",
    "mglearn.discrete_scatter(X_test[:, 0], X_test[:, 1], y_test,\n",
    "                         markers='^', ax=ax)\n",
    "ax.set_xlabel(\"Feature 0\")\n",
    "ax.set_ylabel(\"Feature 1\")\n",
    "ax.legend([\"Train class 0\", \"Train class 1\", \"Test class 0\",\n",
    "                \"Test class 1\"], ncol=4,  loc=(-0.1, 1.1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation in scikit-learn\n",
    "\n",
    "- `cross_val_score` function with learner, training data, labels\n",
    "- Returns list of all scores\n",
    "    - Does 3-fold CV by default\n",
    "    - Default scoring measures are accuracy (classification) or $R^2$ (regression)\n",
    "- Even though models are built internally, they are not returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [ 0.96078431  0.92156863  0.95833333]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "iris = load_iris()\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "scores = cross_val_score(logreg, iris.data, iris.target)\n",
    "print(\"Cross-validation scores: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Change the number of folds with `cv` parameter\n",
    "- Note that there can be quite some _variance_ in the results\n",
    "    - Depends on the stability of the model and the amount of training data\n",
    "    - Typically, the more training data, the more stable the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores: [ 1.          0.96666667  0.93333333  0.9         1.        ]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=5)\n",
    "print(\"Cross validation scores: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation score: 0.96\n"
     ]
    }
   ],
   "source": [
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aggregate the scores yourself (e.g. mean)\n",
    "- This means that the model is 96% accurate _on average_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified K-Fold cross-validation\n",
    "\n",
    "- scikit-learn will use:\n",
    "    - stratified cross-validation by default for classification\n",
    "    - normal cross-validation for regression\n",
    "    - both are non-randomized (samples are not shuffled beforehand)\n",
    "- You can build folds manually with `KFold`\n",
    "    - non-randomized, non-stratified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[ 1.          0.93333333  0.43333333  0.96666667  0.43333333]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5)\n",
    "print(\"Cross-validation scores:\\n{}\".format(\n",
    "      cross_val_score(logreg, iris.data, iris.target, cv=kfold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[ 0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Can you explain this result?\n",
    "kfold = KFold(n_splits=3)\n",
    "print(\"Cross-validation scores:\\n{}\".format(\n",
    "      cross_val_score(logreg, iris.data, iris.target, cv=kfold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[ 0.9   0.96  0.96]\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "print(\"Cross-validation scores:\\n{}\".format(\n",
    "    cross_val_score(logreg, iris.data, iris.target, cv=kfold)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-One-Out cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cv iterations:  150\n",
      "Mean accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=loo)\n",
    "print(\"Number of cv iterations: \", len(scores))\n",
    "print(\"Mean accuracy: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified K-Fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[ 1.          0.93333333  0.43333333  0.96666667  0.43333333]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5)\n",
    "print(\"Cross-validation scores:\\n{}\".format(\n",
    "      cross_val_score(logreg, iris.data, iris.target, cv=kfold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[ 0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Can you explain this result?\n",
    "kfold = KFold(n_splits=3)\n",
    "print(\"Cross-validation scores:\\n{}\".format(\n",
    "      cross_val_score(logreg, iris.data, iris.target, cv=kfold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[ 0.9   0.96  0.96]\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "print(\"Cross-validation scores:\\n{}\".format(\n",
    "    cross_val_score(logreg, iris.data, iris.target, cv=kfold)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias and Variance Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias squared: 14.25, Variance: 0.80, Total error: 15.05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# Data and classifier\n",
    "X, y = make_blobs(centers=2, n_samples=1000, random_state=0)\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Bootstraps\n",
    "n_repeat = 100\n",
    "shuffle_split = ShuffleSplit(test_size=0.33, n_splits=n_repeat)\n",
    "\n",
    "# Store sample predictions\n",
    "y_all_pred = [[] for _ in range(len(y))]\n",
    "\n",
    "# Train classifier on each bootstrap and score predictions\n",
    "for i, (train_index, test_index) in enumerate(shuffle_split.split(X)):\n",
    "    # Train and predict\n",
    "    clf.fit(X[train_index], y[train_index])\n",
    "    y_pred = clf.predict(X[test_index])\n",
    "\n",
    "    # Store predictions\n",
    "    for i,index in enumerate(test_index):\n",
    "        y_all_pred[index].append(y_pred[i])\n",
    "        \n",
    "# Compute bias, variance, error\n",
    "bias_sq = sum([ (1 - x.count(y[i])/len(x))**2 * len(x)/n_repeat \n",
    "            for i,x in enumerate(y_all_pred)])\n",
    "var = sum([((1 - ((x.count(0)/len(x))**2 + (x.count(1)/len(x))**2))/2) * len(x)/n_repeat\n",
    "           for i,x in enumerate(y_all_pred)])\n",
    "error = sum([ (1 - x.count(y[i])/len(x)) * len(x)/n_repeat \n",
    "            for i,x in enumerate(y_all_pred)])\n",
    "\n",
    "print(\"Bias squared: %.2f, Variance: %.2f, Total error: %.2f\" % (bias_sq, var, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 112   size of test set: 38\n",
      "Best score: 0.97\n",
      "Best parameters: {'C': 100, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# naive grid search implementation\n",
    "from sklearn.svm import SVC\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target,\n",
    "                                                    random_state=0)\n",
    "print(\"Size of training set: {}   size of test set: {}\".format(\n",
    "      X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        # for each combination of parameters\n",
    "        # train an SVC\n",
    "        svm = SVC(gamma=gamma, C=C);\n",
    "        svm.fit(X_train, y_train);\n",
    "        # evaluate the SVC on the test set \n",
    "        score = svm.score(X_test, y_test)\n",
    "        # if we got a better score, store the score and parameters\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C': C, 'gamma': gamma}\n",
    "            \n",
    "print(\"Best score: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 84   size of validation set: 28   size of test set: 38\n",
      "\n",
      "Best score on validation set: 0.96\n",
      "Best parameters:  {'C': 10, 'gamma': 0.001}\n",
      "Test set score with best parameters: 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# split data into train+validation set and test set\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    iris.data, iris.target, random_state=0)\n",
    "# split train+validation set into training and validation set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_trainval, y_trainval, random_state=1)\n",
    "print(\"Size of training set: {}   size of validation set: {}   size of test set:\"\n",
    "      \" {}\\n\".format(X_train.shape[0], X_valid.shape[0], X_test.shape[0]))\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        # for each combination of parameters\n",
    "        # train an SVC\n",
    "        svm = SVC(gamma=gamma, C=C)\n",
    "        svm.fit(X_train, y_train)\n",
    "        # evaluate the SVC on the test set \n",
    "        score = svm.score(X_valid, y_valid)\n",
    "        # if we got a better score, store the score and parameters\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C': C, 'gamma': gamma}\n",
    "\n",
    "# rebuild a model on the combined training and validation set,\n",
    "# and evaluate it on the test set\n",
    "svm = SVC(**best_parameters)\n",
    "svm.fit(X_trainval, y_trainval)\n",
    "test_score = svm.score(X_test, y_test)\n",
    "print(\"Best score on validation set: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: \", best_parameters)\n",
    "print(\"Test set score with best parameters: {:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on validation set: 0.64\n",
      "Parameters:  {'C': 10, 'gamma': 0.001}\n",
      "Test set score with best parameters: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import expon\n",
    "\n",
    "param_grid = {'C': expon(scale=100), \n",
    "              'gamma': expon(scale=.1)}\n",
    "random_search = RandomizedSearchCV(SVC(), param_distributions=param_grid,\n",
    "                                   n_iter=20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        iris.data, iris.target, random_state=0)\n",
    "random_search.fit(X_train, y_train)\n",
    "test_score = random_search.score(X_test, y_test)\n",
    "parameters = {'C': C, 'gamma': gamma}\n",
    "print(\"Score on validation set: {:.2f}\".format(score))\n",
    "print(\"Parameters: \", best_parameters)\n",
    "print(\"Test set score with best parameters: {:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for binary classification\n",
    "\n",
    "- The most common (and simple) application of machine learning in practive\n",
    "- We have a positive and a negative class\n",
    "- Different kind of errors:\n",
    "    - False Positive (type I error): model predicts positive while the true label is negative\n",
    "    - False Negative (type II error): model predicts negative while the true label is positive\n",
    "- Which side do you want to err on for a medical test?\n",
    "\n",
    "#### Imbalanced datasets\n",
    "\n",
    "- The type of error plays an even larger role if the dataset is imbalanced\n",
    "    - One class is much more frequent than the other\n",
    "    - This is often typical of real world data\n",
    "    - E.g. credit card fraud detection\n",
    "- Is a 99.99% accuracy good enough? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's create an imbalanced dataset from the handwritten digits dataset by classifying the digit 9 against all others.\n",
    "- Is 90% accuracy still good? Can we do better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "y = digits.target == 9\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.data, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy score: 0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Always predicts majority class\n",
    "dummy = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "pred_dummy = dummy.predict(X_test)\n",
    "print(\"dummy score: {:.2f}\".format(dummy.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg score: 0.98\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=0.1).fit(X_train, y_train)\n",
    "pred_logreg = logreg.predict(X_test)\n",
    "print(\"logreg score: {:.2f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrices\n",
    "\n",
    "- We can represent all predictions (correct and incorrect) in a confusion matrix\n",
    "    - n by n array (n is the number of classes)\n",
    "    - Rows correspond to the true classes\n",
    "    - Columns correspond to the predicted classes\n",
    "    - Each entry counts how often a sample that belongs to the class corresponding to the row was classified as the class corresponding to the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[401   2]\n",
      " [  8  39]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(y_test, pred_logreg)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the confusion matrix can be summarized in several ways\n",
    "\n",
    "- We already know accuracy:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}\n",
    "\\end{equation}\n",
    "\n",
    "__Precision__ is used when the goal is to limit FPs\n",
    "- Clinical trails: you only want to test drugs that really work\n",
    "- Search engines: you want to avoid bad search results\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n",
    "\\end{equation}\n",
    "\n",
    "__Recall__ is used when the goal is to limit FNs\n",
    "- Cancer diagnosis: you don't want to miss a serious disease\n",
    "- Search engines: You don't want to omit important hits\n",
    "- Also know as sensitivity, hit rate, true positive rate (TPR)\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n",
    "\\end{equation}\n",
    "\n",
    "__F1-score__ or F1-measure trades of precision and recall:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{F} = 2 \\cdot \\frac{\\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}}\n",
    "\\end{equation}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
